# Benchmark Configuration
# Copy this file to bench.env and customize for your environment.
# bench.env is gitignored and won't be committed.
#
# To use: cp bench.env.example bench.env
# Then edit bench.env with your settings.

# =============================================================================
# S3 / MinIO Credentials
# =============================================================================
# Leave empty or comment out to use credentials from environment/instance role.
# For local MinIO testing, set these:
AWS_ACCESS_KEY_ID=minioadmin
AWS_SECRET_ACCESS_KEY=minioadmin
AWS_ENDPOINT_URL=http://localhost:9000

# AWS region (required for some S3 operations)
BENCH_AWS_REGION=us-east-1

# =============================================================================
# S3 Bucket and Paths
# =============================================================================
# Local MinIO bucket (default):
BENCH_S3_BUCKET=benchmark
BENCH_S3_PREFIX=tpch
BENCH_OUT_S3_PREFIX=s3://benchmark/outputs

# Production S3 example (uncomment and modify):
# BENCH_S3_BUCKET=my-company-bucket
# BENCH_S3_PREFIX=benchmarks/tpch
# BENCH_OUT_S3_PREFIX=s3://my-company-bucket/benchmarks/outputs

# =============================================================================
# DuckDB Configuration
# =============================================================================
# S3 access method: "httpfs" (faster, needs extension) or "fsspec" (no extension)
BENCH_DUCKDB_S3_METHOD=httpfs

# Execution backend: "python" (in-process) or "cli" (subprocess, avoids ABI issues)
# Use "cli" for airgapped Linux environments where python-duckdb has ABI issues
BENCH_DUCKDB_BACKEND=cli

# =============================================================================
# Benchmark Scale Configuration
# =============================================================================
# TPC-H lineitem sizes: sf=0.1 -> ~7MB, sf=0.5 -> ~36MB, sf=1 -> ~72MB, sf=10 -> ~720MB
#
# SMALL (~100MB max) - for testing on memory-constrained systems:
BENCH_NORMAL_SF="0.1 0.5 1"
BENCH_STRESS_SMALL_BASE_SF=0.1
BENCH_STRESS_SMALL_REPEATS="1 2 4"
BENCH_STRESS_BIG_BASE_SF=1
BENCH_STRESS_BIG_REPEATS="1 2"

# MEDIUM (~1-5GB) - for systems with 16GB+ RAM:
# BENCH_NORMAL_SF="1 2 5 10"
# BENCH_STRESS_SMALL_BASE_SF=1
# BENCH_STRESS_SMALL_REPEATS="1 2 4 8"
# BENCH_STRESS_BIG_BASE_SF=10
# BENCH_STRESS_BIG_REPEATS="1 2 4"

# LARGE (original blog scale, ~140GB+) - for systems with 32GB+ RAM:
# BENCH_NORMAL_SF="10 20 40 80 160 320 640"
# BENCH_STRESS_SMALL_BASE_SF=10
# BENCH_STRESS_SMALL_REPEATS="1 2 4 8 18 36 72"
# BENCH_STRESS_BIG_BASE_SF=640
# BENCH_STRESS_BIG_REPEATS="1 2 4 8 14"

# String table scales (thousands of rows): 10K to 1M
BENCH_STRING_SCALES="10 50 100 500 1000"

# =============================================================================
# Benchmark Run Configuration
# =============================================================================
BENCH_ITERATIONS=3
BENCH_ITERATIONS_WRITE=2
BENCH_ITERATIONS_COPY=1

# =============================================================================
# Output Directories (local)
# =============================================================================
BENCH_OUT_DIR=results_s3
BENCH_OUT_DIR_FILTER_WRITE=results_s3_filter_write
BENCH_OUT_DIR_COPY_PROJECT=results_s3_copy_project
BENCH_OUT_DIR_STRING=results_string
